{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \tnn, lenet, vgg, googlenet, resnet, rnn\n",
    "\n",
    "## nn\n",
    "最简单最基础的网络，有输入层(input layer), 隐藏层 (hidden layers), 输入层 (output layers),，重点理解forward,BP，激活函数\n",
    "\n",
    "## lenet \n",
    "最简单的卷积神经网络，有卷积层，激活函数，池化层和全连接层，全连接层感觉就是一个nn网络。重点理解卷积核怎么提取信息，卷积核的维度大小数量与输入层的关系。\n",
    "\n",
    "## vgg\n",
    "深层网络结构，不断地堆叠卷积层和池化层，几乎全都是用的2*2和3*3的卷积核，减少参数，使结构更深，往往越深效果越好。\n",
    "## GoogLeNet:\n",
    "多并行卷基层（inception模块）。一个 inception 模块的四个并行线路如下： 1.一个 1 x 1 的卷积2.一个 1 x 1 的卷积加上一个 3 x 3 的卷积3.一个 1 x 1 的卷积加上一个 5 x 5 的卷积 4.一个 3 x 3 的最大池化加上 1 x 1 的卷积\n",
    "* 最大池化：改变输入的特征排列\n",
    "* 卷积层：大或小的感受野进行卷积提取特征，小的卷积层（1*1）可以降低输入的特征通道，减少参数计算量\n",
    "\n",
    "## resnet:\n",
    "残差网络结构（f(x)+x)，使用跨层通道使得训练非常深的卷积神经网络成为可能。同样它使用很简单的卷积层配置，使得其拓展更加简单。一定程度上解决了梯度消失和梯度爆炸的问题又不会出现退化问题（regularization解决overfitting但会出现退化问题）\n",
    "\n",
    "\n",
    "## rnn \n",
    "是一类用于处理序列数据（前后数据有紧密联系）的神经网络，和之前的形式有很大区别，也有权值共享和每一个输入值都只与它本身的那条路线建立权连接的特点。和单层的神经网络相似，但是hidden层会受到上个状态hidden层的影响（可能也受下个状态的hidden层的影响）\n",
    "\n",
    "\n",
    "# 常规处理\n",
    "\n",
    "## batch normalization\n",
    "批标准化，就是对于每一层网络的输出，对其做一个归一化，使其服从标准的正态分布，这样后一层网络的输入也是一个标准的正态分布，所以能够比较好的进行训练，加快收敛速度。\n",
    "## regularization\n",
    "loss上再加上\\lambda \\sum_{p \\in params} ||p||_2^2，对参数进行限制，可以看到加完正则项之后会对参数做更大程度的更新，在最简单的nn中可以限制过拟合的出现，以及一定程度上解决了梯度消失和梯度爆炸的问题，但是会出现退化问题（在训练集上的准确率却饱和甚至下降了）\n",
    "## dropout:\n",
    "指在深度学习网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃。注意是暂时，对于随机梯度下降来说，由于是随机丢弃，故而每一个mini-batch都在训练不同的网络。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch里数据的格式\n",
    "\n",
    "## DeepNN\n",
    "```\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(64, 400),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(400, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10)\n",
    ")\n",
    "```\n",
    "out = net(n, m) #输入数据类型 (number of samples, number of neuron)\n",
    "只有一个m， 图片需要展开\n",
    "\n",
    "## convD2\n",
    "```\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "    nn.ReLU(),\n",
    "  \tnn.MaxPool2d(2, 2)\n",
    ")\n",
    "```\n",
    "out = net(n, in_channels, x, y) #(numbers of samples, in_channesls, x of img, y of img)\n",
    "需要输入图片的通道数和长宽\n",
    "\n",
    "## RNN\n",
    "```\n",
    "class rnn_classify(nn.Module):\n",
    "    def __init__(self, in_feature=28, hidden_feature=100, num_class=10, num_layers=2):\n",
    "        super(rnn_classify, self).__init__()\n",
    "        self.rnn = nn.LSTM(in_feature, hidden_feature, num_layers) # 使用两层 lstm\n",
    "        self.classifier = nn.Linear(hidden_feature, num_class) # 将最后一个 rnn 的输出使用全连接得到最后的分类结果\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x 大小为 (batch, 1, 28, 28)，所以我们需要将其转换成 RNN 的输入形式，即 (28, batch, 28)\n",
    "        '''\n",
    "        x = x.squeeze() # 去掉 (batch, 1, 28, 28) 中的 1，变成 (batch, 28, 28)\n",
    "        x = x.permute(2, 0, 1) # 将最后一维放到第一维，变成 (28, batch, 28)\n",
    "        out, _ = self.rnn(x) # 使用默认的隐藏状态，得到的 out 是 (28, batch, hidden_feature)\n",
    "        out = out[-1, :, :] # 取序列中的最后一个，大小是 (batch, hidden_feature)\n",
    "        out = self.classifier(out) # 得到分类结果\n",
    "        return out\n",
    "```\n",
    " 输出是out和h层， out 是 (28, batch, hidden_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WGAN\n",
    "LSGAN(loss-sentive GAN)\n",
    "EBGAN(energy-based GAN)\n",
    "MODE COLLAPSE\n",
    "InfoGAN\n",
    "PG-GAN\n",
    "Condition GAN\n",
    "Cycle GAN, Disco GAN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
